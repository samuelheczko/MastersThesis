{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we run thought the data aquisitin pipeline to get derive results discussed in Samuel Heczko's masters thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import connectome\n",
    "import nibabel as nib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the connectomes from preregistered fmri images\n",
    "In the thesis we largely conducted analysis on thethe Amsterdam Open MRI Collection (AOMIC). We used special preprocessed files and the data proveided by the AOIMIC people. We derive thea analysis in __ steps. All steps are done to all 900 subjects. We loop following proceedure over all atalases considererd.\n",
    "1. Calcluate the time series data for each brain region for each atlas (extract_connectomes.py)\n",
    "2. Compute the connectome of for each subject\n",
    "3. For each atlas save the upper triangle of the connectivity matrix along the information which brain regions are connected in this connection.\n",
    "\n",
    "\n",
    "Let's start with setting up the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defime global parameters\n",
    "cluster = False\n",
    "path = 'data/' ##cahnge for cluster\n",
    "correlation_measure = 'correlation' #can be also tangent, partial\n",
    "res_n = 1\n",
    "res = f'{res_n}x{res_n}x{res_n}'\n",
    "correlation_measure='correlation' ##set for calculation of the brain connectome, choose from 'correlation', 'tangent', 'partial' as implemented by nilearn\n",
    "#templateICBM = '/kyb/agks/sheczko/Downloads/MastersThesis/code/data/templates/mni_icbm152_nlin_asym_09c_nifti/mni_icbm152_nlin_asym_09c/mni_icbm152_t1_tal_nlin_asym_09c.nii' ##use the ICBM T1 template\n",
    "\n",
    "\n",
    "##add the data and names of thigs\n",
    "if cluster:\n",
    "    imgs_paths = glob.glob(path + 'func_images/AOMIC/prep_nifti/*.nii') ##load up a subset of the subejct images\n",
    "\n",
    "else:\n",
    "    imgs_paths = glob.glob(path + 'func_images/AOMIC/prep_nifti/*000*.nii') ##load up all the subejct images\n",
    "subjects_idxs = []\n",
    "for s_n in imgs_paths:\n",
    "    subjects_idxs.append(s_n.split('_')[-1].split('.')[0]) #split the path to extract only the number of the subject from path\n",
    "\n",
    "\n",
    "\n",
    "atlases = glob.glob(path + '/atlases/lawrance2021/label/Human/ICBM/*.nii.gz') ##get the atlases\n",
    "anatomical_labels = glob.glob(path + '/atlases/lawrance2021/label/Human/Anatomical-labels-csv/*.csv') #get the anatomical labels (where available)\n",
    "anatomical_label_names = []\n",
    "for a_l in anatomical_labels:\n",
    "    anatomical_label_names.append(a_l.split('/')[-1].split('.')[0]) #split the path to extract only the name of the atlas\n",
    "\n",
    "\n",
    "##loop over atlases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0008', '0005', '0003', '0006', '0002', '0004', '0001', '0007']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiune with looping over the list of atlases and saving a csv wiht connectivity for all subejcts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS00108\n",
      "DS06481\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m     ana_labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m time_series \u001b[39m=\u001b[39m connectome\u001b[39m.\u001b[39mcalculate_time_series(atlas_path \u001b[39m=\u001b[39m atlas_path,imgs_paths\u001b[39m=\u001b[39mimgs_paths)     \u001b[39m##get the time series of the from all subjects, using the atlas defined\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m correlation_matrices, _ \u001b[39m=\u001b[39m  connectome\u001b[39m.\u001b[39;49mconnectome(time_series \u001b[39m=\u001b[39;49m time_series,correlation_measure\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcorrelation\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#get the connectivity matrices\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df_ \u001b[39m=\u001b[39m connectome\u001b[39m.\u001b[39msave_connectomes_df(correlation_matrices,anatomical_label_presence \u001b[39m=\u001b[39m al_p, anatomic_labels \u001b[39m=\u001b[39m ana_labels,path_to_save \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresults/\u001b[39m\u001b[39m'\u001b[39m, atlas_name \u001b[39m=\u001b[39m atlas_name, n_subjects \u001b[39m=\u001b[39m correlation_matrices\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], correlation_measure \u001b[39m=\u001b[39m correlation_measure,subject_ixds \u001b[39m=\u001b[39m subjects_idxs)\n",
      "File \u001b[0;32m~/Downloads/MastersThesis/code/connectome.py:29\u001b[0m, in \u001b[0;36mconnectome\u001b[0;34m(time_series, correlation_measure)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnectome\u001b[39m(time_series,correlation_measure \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     26\u001b[0m     \u001b[39m##INPUT: the time series on each brain region as list(?) of arrays (for each participant) given by nilearn, the desired correlation type (choose from linear correaltin, partial correlation, tangent correlation)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39m##OUTPUT: signal (standartised)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     connectome_measure \u001b[39m=\u001b[39m ConnectivityMeasure(kind \u001b[39m=\u001b[39m correlation_measure)\n\u001b[0;32m---> 29\u001b[0m     correlation_matrices \u001b[39m=\u001b[39m connectome_measure\u001b[39m.\u001b[39;49mfit_transform(time_series) \n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m correlation_matrices,connectome_measure\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nilearn/connectome/connectivity_matrices.py:569\u001b[0m, in \u001b[0;36mConnectivityMeasure.fit_transform\u001b[0;34m(self, X, y, confounds)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(X) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    565\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTangent space parametrization can only \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mbe applied to a group of subjects, as it returns \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdeviations to the mean. You provided \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m X\n\u001b[1;32m    568\u001b[0m             )\n\u001b[0;32m--> 569\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(X, do_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, do_transform\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    570\u001b[0m                            confounds\u001b[39m=\u001b[39;49mconfounds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nilearn/connectome/connectivity_matrices.py:473\u001b[0m, in \u001b[0;36mConnectivityMeasure._fit_transform\u001b[0;34m(self, X, do_transform, do_fit, confounds)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39m# Compute all the matrices, stored in \"connectivities\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 473\u001b[0m     covariances_std \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_estimator_\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    474\u001b[0m         signal\u001b[39m.\u001b[39m_standardize(x, detrend\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, standardize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    475\u001b[0m         )\u001b[39m.\u001b[39mcovariance_ \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X]\n\u001b[1;32m    476\u001b[0m     connectivities \u001b[39m=\u001b[39m [cov_to_corr(cov) \u001b[39mfor\u001b[39;00m cov \u001b[39min\u001b[39;00m covariances_std]\n\u001b[1;32m    477\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/nilearn/connectome/connectivity_matrices.py:473\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39m# Compute all the matrices, stored in \"connectivities\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcorrelation\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 473\u001b[0m     covariances_std \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcov_estimator_\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    474\u001b[0m         signal\u001b[39m.\u001b[39;49m_standardize(x, detrend\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, standardize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    475\u001b[0m         )\u001b[39m.\u001b[39mcovariance_ \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X]\n\u001b[1;32m    476\u001b[0m     connectivities \u001b[39m=\u001b[39m [cov_to_corr(cov) \u001b[39mfor\u001b[39;00m cov \u001b[39min\u001b[39;00m covariances_std]\n\u001b[1;32m    477\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_shrunk_covariance.py:545\u001b[0m, in \u001b[0;36mLedoitWolf.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocation_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mmean(\u001b[39m0\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[39mwith\u001b[39;00m config_context(assume_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 545\u001b[0m     covariance, shrinkage \u001b[39m=\u001b[39m ledoit_wolf(\n\u001b[1;32m    546\u001b[0m         X \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocation_, assume_centered\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, block_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_size\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshrinkage_ \u001b[39m=\u001b[39m shrinkage\n\u001b[1;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_covariance(covariance)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_shrunk_covariance.py:397\u001b[0m, in \u001b[0;36mledoit_wolf\u001b[0;34m(X, assume_centered, block_size)\u001b[0m\n\u001b[1;32m    394\u001b[0m     _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    396\u001b[0m \u001b[39m# get Ledoit-Wolf shrinkage\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m shrinkage \u001b[39m=\u001b[39m ledoit_wolf_shrinkage(\n\u001b[1;32m    398\u001b[0m     X, assume_centered\u001b[39m=\u001b[39;49massume_centered, block_size\u001b[39m=\u001b[39;49mblock_size\n\u001b[1;32m    399\u001b[0m )\n\u001b[1;32m    400\u001b[0m emp_cov \u001b[39m=\u001b[39m empirical_covariance(X, assume_centered\u001b[39m=\u001b[39massume_centered)\n\u001b[1;32m    401\u001b[0m mu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mtrace(emp_cov)) \u001b[39m/\u001b[39m n_features\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/covariance/_shrunk_covariance.py:315\u001b[0m, in \u001b[0;36mledoit_wolf_shrinkage\u001b[0;34m(X, assume_centered, block_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m     cols \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(block_size \u001b[39m*\u001b[39m j, block_size \u001b[39m*\u001b[39m (j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m    314\u001b[0m     beta_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mdot(X2\u001b[39m.\u001b[39mT[rows], X2[:, cols]))\n\u001b[0;32m--> 315\u001b[0m     delta_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49mdot(X\u001b[39m.\u001b[39;49mT[rows], X[:, cols]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m    316\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39mslice\u001b[39m(block_size \u001b[39m*\u001b[39m i, block_size \u001b[39m*\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m    317\u001b[0m beta_ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mdot(X2\u001b[39m.\u001b[39mT[rows], X2[:, block_size \u001b[39m*\u001b[39m n_splits :]))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for atlas_path in atlases: ##loop over atlases\n",
    "    atlas_name = (atlas_path.split('/')[-1].split('.')[0].split('_')[0]) #split the atlas path so we\n",
    "    print(atlas_name)\n",
    "    al_p = (any(n == atlas_name for n in anatomical_label_names)) ##find wheter we have the anatomical labellings for this atlas\n",
    "\n",
    "    if al_p:\n",
    "        anatomic_path = path + f'/atlases/lawrance2021/label/Human/Anatomical-labels-csv/' + atlas + '.csv'\n",
    "        ana_labels = pd.read_csv(anatomic_path,names=colnames, header=None)\n",
    "    else:\n",
    "        ana_labels = None\n",
    "\n",
    "\n",
    "    time_series = connectome.calculate_time_series(atlas_path = atlas_path,imgs_paths=imgs_paths)     ##get the time series of the from all subjects, using the atlas defined\n",
    "\n",
    "    correlation_matrices, _ =  connectome.connectome(time_series = time_series,correlation_measure='correlation') #get the connectivity matrices\n",
    "\n",
    "    df_ = connectome.save_connectomes_df(correlation_matrices,anatomical_label_presence = al_p, anatomic_labels = ana_labels,path_to_save = path + 'results/', atlas_name = atlas_name, n_subjects = correlation_matrices.shape[0], correlation_measure = correlation_measure,subject_ixds = subjects_idxs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
